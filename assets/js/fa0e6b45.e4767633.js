"use strict";(self.webpackChunkcadence=self.webpackChunkcadence||[]).push([[1328],{1096:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"use-cases/batch-job","title":"Batch job","description":"Batch job","source":"@site/docs/02-use-cases/06-batch-job.md","sourceDirName":"02-use-cases","slug":"/use-cases/batch-job","permalink":"/Cadence-Docs/docs/use-cases/batch-job","draft":false,"unlisted":false,"editUrl":"https://github.com/cadence-workflow/Cadence-Docs/tree/master/docs/02-use-cases/06-batch-job.md","tags":[],"version":"current","lastUpdatedBy":"David Porter","lastUpdatedAt":1744238220000,"sidebarPosition":6,"frontMatter":{"layout":"default","title":"Batch job","permalink":"/docs/use-cases/batch-job"},"sidebar":"docsSidebar","previous":{"title":"Storage scan","permalink":"/Cadence-Docs/docs/use-cases/partitioned-scan"},"next":{"title":"Infrastructure provisioning","permalink":"/Cadence-Docs/docs/use-cases/provisioning"}}');var a=n(4848),r=n(8453);const o={layout:"default",title:"Batch job",permalink:"/docs/use-cases/batch-job"},s=void 0,c={},l=[{value:"Batch job",id:"batch-job",level:2},{value:"Use Case:",id:"use-case",level:4},{value:"Batch jobs with heartbeating",id:"batch-jobs-with-heartbeating",level:2},{value:"Considerations before starting",id:"considerations-before-starting",level:3},{value:"What problems this solves",id:"what-problems-this-solves",level:3},{value:"High level concept:",id:"high-level-concept",level:3}];function h(e){const t={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h2,{id:"batch-job",children:"Batch job"}),"\n",(0,a.jsx)(t.p,{children:"A lot of batch jobs are not pure data manipulation programs. For those, the existing big data frameworks are the best fit. Cadence is a more general orchestration mechanism and doesn't provide native SQL or worker data shuffle functionality out of the box, engineers wishing to rely on these would need to implement this functionality themselves.\nBut if processing a record requires external API calls that might fail and potentially take a long time, Cadence might be preferable."}),"\n",(0,a.jsx)(t.h4,{id:"use-case",children:"Use Case:"}),"\n",(0,a.jsx)(t.p,{children:"One of our internal Uber customers use Cadence for end of month statement generation. Each statement requires calls to multiple microservices and some statements can be really large. Cadence was chosen because it provides hard guarantees around durability of the financial data and seamlessly deals with long running operations, retries, and intermittent failures."}),"\n",(0,a.jsx)(t.h2,{id:"batch-jobs-with-heartbeating",children:"Batch jobs with heartbeating"}),"\n",(0,a.jsxs)(t.p,{children:["Cadence is able to coordinate, restart and track progress of large batch jobs by keeping track of their incremental progress and allowing them to resume if they're stopped for any reason. This predominantly relies on the ",(0,a.jsx)(t.code,{children:"heartbeat"})," feature and activity retries."]}),"\n",(0,a.jsx)(t.p,{children:"This is used in production for customers who wish to work through large batch workloads"}),"\n",(0,a.jsx)(t.h3,{id:"considerations-before-starting",children:"Considerations before starting"}),"\n",(0,a.jsx)(t.p,{children:"Heartbeating cadence activities are activities who emit their progress at an appropriate interval (usually every few seconds) indicating where they are up to. Optionally, they may use progress information (like an offset number or iterator) to resume their progress. However, this necessarily implies that:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"If activities get restarted, they may redo some work, so this is not suitable for non-idempotent operations."}),"\n",(0,a.jsx)(t.li,{children:"The activity will be handling all the progress, so apart from heartbeat information, debugging about the granular operations being performed is not necessarily visible as compared by doing each operation in a distinct activity."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"what-problems-this-solves",children:"What problems this solves"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"This is for high-throughput operations where work may able to fit into a single long-running activity, or partitioned across multiple activities which can run for a longer duration."}),"\n",(0,a.jsx)(t.li,{children:"This addresses problems customers may have running workflows which are returning large blocks of data where the data is hitting up against Cadence activity limits"}),"\n",(0,a.jsx)(t.li,{children:"Because heartbeat data is only temporarily recorded, this is a good way avoid hitting Cadence workflow limits on the number of history events: there only is a single activity which is long running vs many small short-lived activities (each of which needs multiple history events)."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"high-level-concept",children:"High level concept:"}),"\n",(0,a.jsx)(t.p,{children:"The idea is to create an activity which will handle a lot of records and record its progress:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-golang",children:'func (a *ABatchActivity) Execute(ctx context.Context, params Params) error {\n\n    // in this case this is just a struct with a mutex protecting it\n    var state State\n    if activity.HasHeartbeatDetails(ctx) {\n        // when starting the activity, check at start time for a previous iteration \n        err := activity.GetHeartbeatDetails(ctx, &state)\n        if err != nil {\n            return err\n        }\n        log.Info("resuming from a previous state", zap.Any("state", state))\n    }\n\n    // in the background, every 5 seconds, emit where we\'re up to\n    // so the cadence server knows the activity is still alive, and \n    // put the progress in the recordheartbeat call so it can be pulled in\n    // if we have to restart\n    go func() {\n        ticker := time.NewTicker(time.Seconds * 5)\n        defer ticker.Stop()\n        for {\n            select {\n            case <-ctx.Done():\n                return\n            case <-ticker.C:\n                reportState := state.Clone()\n                activity.RecordHeartbeat(ctx, reportState)\n            }\n        }\n    }()\n\n    // here in this example, we may assume this is several thousand \n    // records which will take a while to get through. Importantly, \n    // if we have to restart, don\'t start from the beginning, use the \n    // offset so we don\'t redo work.\n    batchDataToProcess := a.DB.GetDataFromOffset(state.GetOffset())\n\n    // go through and process all the records through whatever side-effects are appropriate\n    for i := range batchDataToProcess {\n        a.rpc.UpdateRecord(i)\n        state.Finished(i)\n    }\n    return nil\n}\n'})}),"\n",(0,a.jsx)(t.p,{children:"And run this activity in a workflow with settings:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-golang",children:'// an example configuration for setting activity options to \n// retry if the activity gets stopped for any reason\nfunc setActivityOptions(ctx workflow.Context) workflow.Context {\n\n    ctx = workflow.WithActivityOptions(ctx, workflow.ActivityOptions{\n        ScheduleToStartTimeout: time.Minute,           // how long we expect this task to sit waiting to be picked up. \n                                                       // Typically subseconds unless heavily contended\n        StartToCloseTimeout:    time.Hour,             // however long this activity is expected to take, maximum, from end to end. \n                                                       // This is workload dependent\n        HeartbeatTimeout:       time.Second * 30,      // How long we should wait before deciding to restart the activity because the \n                                                       // background thread hasn\'t checked in. Half a a minute is probably a bit \n                                                       // overgenous. In the example above we\'re picking 5 seconds to heartbeat\n        \n        // It is unrealistic to assume that a long running activity will succeed\n        // so add a retry-policy to restart it when there\'s a failure. \n        RetryPolicy: &workflow.RetryPolicy{\n            InitialInterval:          time.Second,\n            MaximumInterval:          time.Minute * 10,\n            MaximumAttempts:          10,               // we expect this to have to restart a maximum of 10 times before giving up. \t\n        },\n    })\n    return ctx\n}\n\nfunc Workflow(ctx workflow.Context, config entity.Config) error {\n\n    log := workflow.GetLogger(ctx)\n    ctx = setActivityOptions(ctx, config)\n    err := workflow.ExecuteActivity(ctx, ABatchActivityName, config).Get(ctx, nil)\n    if err != nil {\n        log.Error("failed to execute activity", zap.Error(err), zap.Any("input", config))\n\n    }\n\n    log.Info("Workflow complete")\n    return nil\n}\n'})})]})}function d(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>s});var i=n(6540);const a={},r=i.createContext(a);function o(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);